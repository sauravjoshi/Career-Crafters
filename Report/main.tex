\documentclass[a4paper,10pt]{article}

\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{geometry}
\geometry{a4paper, left=2cm, right=2cm, top=1.5cm, bottom=3cm }
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{natbib}

\usepackage{etoolbox,fancyhdr,xcolor}
\newcommand{\headrulecolor}[1]{\patchcmd{\headrule}{\hrule}{\color{#1}\hrule}{}{}}
\newcommand{\footrulecolor}[1]{\patchcmd{\footrule}{\hrule}{\color{#1}\hrule}{}{}}
\renewcommand{\headrulewidth}{1pt}
\headrulecolor{red!100}%
\renewcommand{\footrulewidth}{1pt}
\footrulecolor{red!100}%

\fancyhf{}
\fancyhead[R]{\includegraphics[width=0.07\textwidth]{figures/UIC.jpg}}

\fancyfoot[L]{Project: Career Crafters}
\fancyfoot[C]{College of Engineering, Computer Science}
\fancyfoot[R]{\thepage}

\setlength{\headheight}{15mm}
\pagestyle{fancy}

\bibliographystyle{apalike}

\usepackage{times}
\begin{document}

\noindent 
\begin{center}
\textbf{{\Large CAREER CRAFTERS}} \\
\end{center}

\noindent 
\textbf{Authors: Saurav Joshi, Venkata Sesha Phani Vakicherla, Shahbaz Syed, Usha Pulivarthi, Venkata Rama Surya Sesha Siva Kumar Pidaparthi} \textit{University of Illinois, Chicago, IL}
\\

\noindent 
\textbf{ABSTRACT: } The job search process is daunting due to the vast number of opportunities available online. To simplify this process, our team developed Career Crafters, a web application that not only tells job seekers how closely their skills match a job but also actively recommends the best job matches based on their resumes. This report details our approach, which combines data cleaning, machine learning techniques, and statistical analyses to provide highly personalized job recommendations, proving to be a valuable tool for job seekers.

\noindent 
\textbf{KEYWORDS:} Job Matching, Machine Learning, Recommendation Systems, Data Preprocessing, Natural Language Processing, Interactive Web Application.

\section{INTRODUCTION}

In today’s job market, finding the right job is often as challenging as getting the job itself. While existing job search tools focus on indicating how well a candidate's qualifications match a job listing, they fall short in actively guiding users to their best matches. Career Crafters addresses this gap by offering a more proactive solution. Our system uses advanced machine learning to analyze job postings and candidate resumes, ensuring that job seekers get recommendations that are not just close matches but the best possible options for their skills and experiences. This report will discuss how Career Crafters was built, from initial data handling to the deployment of personalized job recommendations, highlighting its advantages in helping candidates efficiently find suitable jobs.

\textbf{Github Project Link: } \hyperlink{https://github.com/sauravjoshi/Career-Crafters}{https://github.com/sauravjoshi/Career-Crafters}

% \subsection{Secondary Heading or Sub-headings}

% Here we have a sub-heading. There is no blank line after the sub-heading. You can have one level of subheadings but not a third i.e. you cannot have Section 1.1.1 as a subheading.

% \begin{itemize}
%     \item If you want to list bullet points you can do so;
%     \item This is the second point;
%     \item This is a third bullet point;
%     \item A fourth bullet point;
%     \item But you can.
% \end{itemize}   

% After a list you must leave a single blank line and remember to add the indent if you are starting a new paragraph.

% \subsection{Another sub-heading}

% You can have as many sub-headings in a section as you want to. Note that sub-headings have a 6pt spacing after them rather than a blank line but they are preceded by a blank line. The number of sections and sub-sections is up to you, as are the titles of each of them and this will be driven by the content of your report.

\section{DATA Processing}

\subsection{Data Collection}

    \subsubsection{Data Description}
    The Career Crafters application utilizes a comprehensive dataset of 32641 job postings, which were sourced from Kaggle and then merged to form a consolidated database suitable for analysis. The data comprises 11 attributes such as Job Title, Company Name, Job Location, and more, all of which are essential for developing accurate job recommendations.

    \subsubsection{Data Acquisition}
    \begin{itemize}
        \item \textbf{Master Data:} The data was acquired from Kaggle from different sources and merged based on relevant features to create a master set. \hyperlink{https://drive.google.com/file/d/12r3pCPnpawmdEmWB34k7UO1IjS2t4o34/view?usp=sharing}{https://drive.google.com/file/d/12r3pCPnpawmdEmWB34k7UO1IjS2t4o34/view?usp=sharing}
        \item \textbf{Software Engineer:} \hyperlink{https://www.kaggle.com/datasets/asaniczka/software-engineer-job-postings-linkedin}{https://www.kaggle.com/datasets/asaniczka/software-engineer-job-postings-linkedin}
        \item \textbf{Data Engineer:} \hyperlink{https://www.kaggle.com/datasets/asaniczka/linkedin-data-engineer-job-postings}{https://www.kaggle.com/datasets/asaniczka/linkedin-data-engineer-job-postings}
        \item \textbf{Data Analyst:} \hyperlink{https://www.kaggle.com/datasets/asaniczka/data-analyst-job-postings}{https://www.kaggle.com/datasets/asaniczka/data-analyst-job-postings}
        \item \textbf{Data Scientist:} \hyperlink{https://www.kaggle.com/datasets/asaniczka/data-scientist-linkedin-job-postings}{https://www.kaggle.com/datasets/asaniczka/data-scientist-linkedin-job-postings}
    \end{itemize}

    
    \subsubsection{Column Types and Data Characteristics}
        \begin{itemize}
        \item job\_title, company, job\_location, job\_link, first\_seen, search\_city, search\_country, job level, job\_type, job\_summary, job\_skills: All of these columns were string value. 
        \item First Seen: This column is Datetime, indicating when the job was first posted or collected.
        \item Derived Numerical Data: Post-processing, geo-coordinates were derived from the 'job\_location' text to facilitate spatial analysis.
    \end{itemize}   

\subsection{Data Wrangling}
    \subsubsection{Cleaning and Pre-Processing}
    Initial data cleaning involved string and list handling, where all attributes were cleansed to remove irrelevant characters and spaces ensuring clean and usable text for analysis. Specifically, the `job\_summary` and `job\_skills` attributes, which had 411 and 1273 NA entries respectively, were removed to maintain the integrity of the dataset as imputing them or deriving them was not feasible.

    \subsubsection{Irregularities Handling}
        \begin{itemize}
        \item  Since the source data was scraped from LinkedIn, it was free-flow data. There were irregularities present in the job\_title such as Sr. Data Engineer and Senior Data Engineer is effectively the same. Also for the job title Senior Data Engineer, Public Company and Senior Data Engineer are effectively the same. 
        \item Also the job\_locations were not in a set format. This feature was also important to us for geospatial analysis of job distribution. There were some job postings without proper addressing. Also since we had data from countries such as the UK, Australia, and Canada, this made having a uniform format even more difficult.
        \item  Custom scripts were written specifically for these tasks that cater to the variance in these data and extract relevant information.
    \end{itemize}
    
    \subsubsection{Text Preprocessing (done over job\_skills\_summary)}
    \begin{itemize}
        \item \textbf{Tokenization and Normalization:} Job descriptions and skills were broken down into tokens and normalized to lowercase to standardize the data.
        \item \textbf{Stop Words Removal:} Common stop words were removed to emphasize more significant terms relevant to job skills.
        \item \textbf{Punctuation Handling:} Punctuation marks were removed as they can interfere with text processing tasks like vectorization.
        \item \textbf{Part-of-Speech (POS) Tagging:} Words were tagged according to their parts of speech (e.g., noun, verb, adjective). We extracted clean POS from the initially tagged POS token by removing tokens with only 1 character. This gives us the final cleaned token. Certain specific tokens are also removed such as "company", "description", "title", "job", and "skills", as these are junk for a job\_description field. 
        \item \textbf{Lemmatization:} Words were reduced to their base form, aiding in uniformity and effectiveness in matching processes. Finally, lemmatization is done over the cleaned token which are joined back to form the final processed job\_description string.
        \item \textbf{Vectorization:} Finally, the text was converted into a numeric format using vectorization techniques to feed textual data into machine learning algorithms.
    \end{itemize}
    
    \subsubsection{Feature Engineering}
    \begin{itemize}
        \item \textbf{Geo Code Retrieval:} After handling the irregularities as described above, once standardized, geo-coordinates for each job posting were retrieved. This enabled precise geospatial analysis of job distribution, facilitating insights into regional employment trends and opportunities.
        \item \textbf{Interpolating job\_skills to job\_desc:} To consolidate and enhance the information available for our recommendation model, 'job\_skills' were combined with 'job\_summary' to create a new column called 'job\_skills\_summary'. This column integrates all critical skill-related information with the job descriptions, providing a unified data point that enhances the effectiveness of our job matching algorithms by ensuring a comprehensive dataset for analysis.
    \end{itemize}
    
\section{EDA}
    
 \subsection{Heatmap of Job Locations}

      Figure \ref{fig_heatmap} heatmap shows us the job locations that are present across different countries. The jobs seem to be more concentrated over West \& Mid-West of America than Easts, Almost the entirety in Australia towards the East-coast, mostly in London, Manchester and Birmingham in UK and interestingly almost every job in Canada, comes with a location at a closer proximity with US such as at Vancouver and Montreal. This visualization in turn gives rise to knowing what jobs are prevalent in which regions.

    \begin{figure}[ht]
    \centering
    \includegraphics[height=6.6cm]{figures/HeatMap.png}
    \caption{An interesting plot (note that figure captions go BELOW THE FIGURE). Visualization 1: Saurav Joshi}
    \label{fig_heatmap}
    \end{figure}


 \subsection{Dominant jobs based on cities}
      Figure \ref{fig_dominant_jobs} shows us the job locations that are present across different countries. The concentration of points illustrates the relative number of jobs in each region, giving a visual representation of job availability and market demand. The clusters of job points may correlate with economic centers and tech hubs, suggesting where certain industries are thriving. This can allow candidates to target specific cities which are having more job postings as per their required job title.

    \begin{figure}[ht]
    \centering
    \includegraphics[height=6.6cm]{figures/dominant.png}
    \caption{An interesting plot (note that figure captions go BELOW THE FIGURE). Visualization 2: Saurav Joshi}
    \label{fig_dominant_jobs}
    \end{figure}

 \subsection{Job Postings and Resume in 2D t-SNE Space}
      Figure \ref{fig_tsne} shows us resume vs recommendation vs non-recommended jobs in a two-dimensional t-SNE space. The cluster of blue dots near the 'X' suggests that the top recommendations are indeed closely aligned with the resume's features.

    \begin{figure}[ht]
    \centering
    \includegraphics[height=6.6cm]{figures/17.png}
    \caption{Job Postings VS Recommended Jobs vs Resume. Visualization 3: Saurav Joshi}
    \label{fig_tsne}
    \end{figure}
    

\subsection{Resume specific Top skills for recommended jobs}

Figure \ref{fig_phani_1} shows a visualization of the top skills extracted from candidates' resumes and how these skills align with those required by jobs recommended by our system. This analysis helps to demonstrate the effectiveness of our matching algorithm in identifying and recommending positions that best fit the candidates' skill sets.

    \begin{figure}[ht]
    \centering
    \includegraphics[height=6.6cm]{figures/Vis_1_Phani.png}
    \caption{Resume specific Top skills for recommended jobs. Visualization 1: Phani}
    \label{fig_phani_1}
    \end{figure}

\subsection{Top 10 Job Skills}
Figure \ref{fig_top_10} The bar chart ranks the top 10 normalized job skills in frequency, with 'SQL' and 'Python' leading the chart, indicative of their high demand in the tech industry. Skills in 'data analysis' and 'java' are also prevalent, while 'communication' skills are emphasized as essential. This information is crucial for job seekers aiming to prioritize their learning and development focus areas.

    \begin{figure}[ht]
    \centering
    \includegraphics[height=6cm]{figures/13.png}
    \caption{Bar chart ranks the top 10 normalized job skills in frequency. Visualization 2: Phani}
    \label{fig_top_10}
    \end{figure}

\subsection{Job Level and Type Cross-tabulation}
Figure \ref{fig_cross_tab} visualizes a cross-tabulation of job levels against job types. - Mid-senior level roles dominate, especially in the onsite category, indicating a mature job market.
Associate roles are fewer in comparison, with hybrid roles outnumbering remote opportunities at this level. This data could inform job seekers about the most prevalent job types at different career stages.

    \begin{figure}[ht]
    \centering
    \includegraphics[height=6cm]{figures/11.png}
    \caption{Cross-tabulation of job levels against job types. Visualization 3: Phani}
    \label{fig_cross_tab}
    \end{figure}



\section{Machine Learning and Statistical Analysis}

Each member of the Career Crafters team utilized at least one advanced machine learning or statistical analysis technique to analyze the data and extract meaningful insights:

\subsection{Saurav Joshi: GloVe Embedding, Cosine Similarity Match, and K-Nearest Neighbors (K-NN)}
\textbf{Technique Used:} GloVe Embedding\\
\textbf{Description:} Manually trained a Word2Vec model to create word embeddings that capture semantic meanings of the skills and job titles within the dataset. The model settings included 100 dimensions, a window size of 5, and a minimum count of 2, running on 4 threads.\\
\textbf{Inferences:} The embeddings helped in understanding the relationship between different skills and job titles, enabling the recommendation system to suggest jobs that closely match candidates' profiles based on semantic similarity.

\textbf{Additional Technique: Cosine Similarity Match}\\
\textbf{Description:} Utilized cosine similarity to measure the distance between the vectorized features of job postings and candidate resumes. This method assesses the cosine of the angle between two vectors in a multi-dimensional space, providing a similarity score that is crucial for effective job matching.\\
\textbf{Inferences:} This similarity metric has proven essential in filtering and ranking job postings that are most relevant to the candidates' skills and experiences, significantly enhancing the precision of our recommendations.

\textbf{Additional Technique: K-Nearest Neighbors (K-NN)}\\
\textbf{Description:} Applied the K-NN algorithm to classify job postings based on the closest feature vectors derived from resumes. This method uses the calculated cosine similarity scores to determine the 'k' most similar job postings to a given candidate's profile.\\
\textbf{Inferences:} K-NN has been effective in narrowing down the list of potential job matches to those that best fit the candidates' qualifications and preferences, thereby optimizing the

\textbf{Additional Visualization: Job Recommendations Comparison based on KNN Match distance: }\\
\textbf{Description:} This figure \ref{fig_comparison} displays top job matches providing a snapshot of the recommendation system’s output based on candidates resume.\\
\textbf{Inferences:} The varied job types and levels across different cities suggest the system's capability to personalize job recommendations effectively, catering to diverse candidate profiles and preferences.

 \begin{figure}[ht]
    \centering
    \includegraphics[height=5.5cm]{figures/Comparison.png}
    \caption{KNN - Match Distances - Saurav Joshi}
    \label{fig_comparison}
    \end{figure}
\subsection{Venkata Sesha Phani Vakicherla: Word2Vec Embedding, Visualizations of Top Job Matches, Recommended vs Non Recommended Jobs}
\textbf{Technique Used:} Word2Vec Embedding\\
\textbf{Description:} Implemented Word2Vec to generate word embeddings by aggregating global word-word co-occurrence matrix from the job postings. The Word2Vec model was trained over 4 epochs with similar settings as GloVe.\\
\textbf{Inferences:} This technique provided insights into common skill requirements across different jobs, enhancing the system's ability to match job seekers with roles that require similar skills, even if the job titles differ.

\textbf{Additional Visualization: 3D Scatter Plot: Resume vs Recommended Jobs vs Non Recommended Jobs}\\
\textbf{Description:} This 3D scatter plot \ref{fig_scat_plot} visualizes the distinction between recommended (blue) and non-recommended (gray) job postings relative to a candidate’s resume, within a compressed feature space. \\
\textbf{Inferences:} The proximity of blue points to the resume indicates accurate recommendations by the system, while the dispersed gray points reflect lesser relevance to the candidate's profile.

    \begin{figure}[ht]
    \centering
    \includegraphics[height=6.6cm]{figures/Phani_3D_ScatterPlot.png}
    \caption{3D Scatter Plot: (System Recommended) Resume vs Recommended Jobs. Visualization 4: Phani}
    \label{fig_scat_plot}
    \end{figure}

\textbf{Additional Visualization: Top Job Matches based on Resume}\\
\textbf{Description:} This figure \ref{fig_table} displays top job matches providing a snapshot of the recommendation system’s output based on candidates resume.\\
\textbf{Inferences:} The varied job types and levels across different cities suggest the system's capability to personalize job recommendations effectively, catering to diverse candidate profiles and preferences.

 \begin{figure}[ht]
    \centering
    \includegraphics[height=6cm]{figures/Phani_Table.png}
    \caption{Table: Top Job Matches based on Resume (note that figure captions go BELOW THE FIGURE). Visualization 5: Phani}
    \label{fig_table}
    \end{figure}

\subsection{Shahbaz: Resume Parser}
\textbf{Technique Used:} K-Nearest Neighbors (K-NN) with Cosine Similarity\\
\textbf{Description:} Applied K-NN using cosine similarity to match resumes with job postings based on the similarity of their feature vectors derived from TF-IDF scores.\\
\textbf{Inferences:} This method proved effective in ranking job recommendations by relevance, allowing the system to prioritize jobs that best fit the candidates' skills and experiences.

\subsection{Usha: TF-IDF Vectorization}
\textbf{Technique Used:} TF-IDF Vectorization\\
\textbf{Description:} Used TF-IDF to transform text data into a vectorized format, weighting terms based on their importance to a document relative to the entire dataset.\\
\textbf{Inferences:} The analysis identified key terms and skills that are critical in different industries, which helped in tailoring job recommendations to specific sectoral needs.

\subsection{Venkat: CountVectorizer}
\textbf{Technique Used:} CountVectorizer\\
\textbf{Description:} Employed CountVectorizer as a baseline to convert text data into a matrix of token counts, allowing comparison against more sophisticated models.\\
\textbf{Inferences:} While basic, this approach provided a foundational understanding of the frequency of various job-related terms, which assisted in initial filtering and categorization of job postings.

\section{Results}

The recommendation engine and the accompanying web application form the core of the Career Crafters project's results. They ease job search by offering a personalized, data-driven service that is not only functional but also engaging and user-centric by using the system's ability to match job seekers with the right opportunities based on a nuanced understanding of their skills and job market trends.

 \begin{figure}[ht]
    \centering
    \includegraphics[height=4cm]{figures/Results.png}
    \caption{Results (note that figure captions go BELOW THE FIGURE)}
    \label{fig_results}
    \end{figure}

\begin{itemize}
    \item Total 7 Resumes considered for checking efficacy amongst top 5 recommendations for each embedding using K-NN.

    \item  Relevant Skills and Relevant Titles are matched using a Fuzzy String matching.
    \begin{itemize}
    	\item Skills with a partial\_ratio of greater than 80\%.
    	\item Titles with a partial\_ratio of greater than 90\%.
    \end{itemize}
\end{itemize}

\textbf{Embedding Techniques Comparison}:
\begin{itemize}
 \item A comparison of embedding techniques revealed that GloVe outperformed others with an 80\% match for relevant skills and an 85.71\% match for job titles. This high performance indicates a strong alignment between the job recommendations provided by the system and the candidates' profiles and preferences.

 \item Word2Vec also showed promising results, especially in matching relevant job titles with a match percentage of 82.85\%, indicating its effectiveness in capturing the context of job descriptions and titles .
\end{itemize}

\textbf{Analysis of Recommendation System}:
\begin{itemize}
 \item The system was tested with a set of 7 resumes, evaluating the top 5 recommendations for each resume against various embeddings using the K-NN algorithm. This practical approach to testing helped fine-tune the recommendation engine for precision.

 \item The relevance of the matches was determined using a fuzzy string matching algorithm, with a partial ratio threshold set to ensure only the most appropriate recommendations were considered successful. Skills and titles meeting these criteria underscore the tailored nature of the job matching process.

\end{itemize}

\subsection{Interactive Web Application}

A key outcome of the project is an interactive web application that showcases the recommendation engine in real-time operation. This user-friendly interface allows job seekers to experience firsthand the sophistication of the recommendation system. Through the web application, users can submit their resumes and instantly receive job recommendations.

The web application's front end is built using React with TypeScript, styled with Tailwind CSS, and integrates react-plotly for dynamic data visualization. The back end is developed in Python using the Flask framework, with vector models for the recommendation engine stored in files to facilitate quick and efficient data processing.

The source code and additional documentation are available on GitHub at: \href{https://github.com/sauravjoshi/Career-Crafters}{https://github.com/sauravjoshi/Career-Crafters}. Demo available at: \url{https://www.youtube.com/watch?v=JDnYAXXDxpU}

\subsection{Limitations}
While Career Crafters has made significant strides in job matching, the following limitations are acknowledged:
\begin{itemize}
  \item The recommendation engine's adaptability to the complexities and nuances of varied job roles across different industries has room for enhancement.
  \item The system currently does not incorporate a real-time data syncing mechanism, which could potentially limit the reflection of immediate market changes.
\end{itemize}

\subsection{Recommendations for Further Work}
Based on the project's roadmap and current limitations, the following future work is proposed:
\begin{itemize}
  \item \textbf{Advanced BERT Embeddings:} Employ more sophisticated BERT embeddings to improve contextual understanding within job descriptions, increasing the precision of job matches.
  \item \textbf{Content-Based Clustering:} Investigate content-based clustering approaches for recommendations to effectively group similar jobs and candidate profiles, allowing for refined and tailored matches.
  \item \textbf{Continuous Data Ingestion:} Develop a pipeline for the continuous updating of the job postings corpus to maintain data relevance and accuracy.
  \item \textbf{Feedback Ingestion:} Integrate user feedback mechanisms into the system to capture user preferences and interactions, facilitating the personalization and continuous improvement of the recommendation algorithms.
\end{itemize}

\section*{Acknowledgments}

We express our deepest gratitude to Professor Saurav Medya for his invaluable guidance and continuous support throughout the duration of this project. His insights and expertise were instrumental in shaping the direction and success of our work. Special thanks to the teaching assistants, Peyman and Khushboo, whose assistance and dedication played a pivotal role in our research and development process. Their feedback and suggestions were greatly appreciated and contributed significantly to the refinement of the Career Crafters system.

We would also like to extend our thanks to the University of Illinois at Chicago (UIC) for providing the resources and environment conducive to our academic and project pursuits. The support and opportunities offered by UIC have been essential to our learning and success.

\end{document}


\end{document}